[main]
name="translation"
tf_manager=<tf_manager>
output="output-4GB"
batch_size=256
epochs=100
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner_greedy>]
evaluation=[("target_greedy", "target", <bleu>)]
val_preview_num_examples=10
val_preview_input_series=["source", "target", "source_bpe", "target_bpe"]
val_preview_output_series=["target_greedy"]
logging_period=80
validation_period=2000
random_seed=333

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[bpe_preprocess]
class=processors.bpe.BPEPreprocessor
merge_file="./merge_file.bpe"

[bpe_postprocess]
class=processors.bpe.BPEPostprocessor

[bleu]
class=evaluators.bleu.BLEUEvaluator

[train_data]
class=dataset.load_dataset_from_files
s_source="./full.src"
s_target="./full.trg"
preprocessors=[("source", "source_bpe", <bpe_preprocess>), ("target", "target_bpe", <bpe_preprocess>)]
lazy=True

[val_data]
class=dataset.load_dataset_from_files
s_source="./dev.src"
s_target="./dev.trg"
preprocessors=[("source", "source_bpe", <bpe_preprocess>), ("target", "target_bpe", <bpe_preprocess>)]

[shared_vocabulary]
class=vocabulary.from_bpe
path="./merge_file.bpe"

[encoder]
class=encoders.sentence_encoder.SentenceEncoder
name="encoder"
rnn_size=350
max_input_len=50
embedding_size=300
dropout_keep_prob=0.8
attention_type=decoding_function.Attention
data_id="source_bpe"
vocabulary=<shared_vocabulary>

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<encoder>]
rnn_size=350
embedding_size=300
use_attention=True
dropout_keep_prob=0.8
data_id="target_bpe"
max_output_len=50
vocabulary=<shared_vocabulary>
conditional_gru=True

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-08
clip_norm=1.0

[runner_greedy]
class=runners.runner.GreedyRunner
output_series="target_greedy"
decoder=<decoder>
postprocess=<bpe_postprocess>

